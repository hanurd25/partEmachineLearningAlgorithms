{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#This section is for datacollection\n",
    "#The dataset is found here ---->   https://archive.ics.uci.edu/dataset/410/paper+reviews\n",
    "#The dataset is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license\n",
    "#github push test\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statistics\n",
    "filePath = 'dataset/reviews.json'\n",
    "\n",
    "\n",
    "decisionCounts = {\n",
    "    'accept': 0,\n",
    "    'probably reject': 0,\n",
    "    'reject': 0,\n",
    "    'no decision': 0\n",
    "}\n",
    "\n",
    "\n",
    "evaluations = []\n",
    "confidences = []\n",
    "orientations = []\n",
    "missingValuesPositions = []\n",
    "nullValuesCount= 0\n",
    "\n",
    "# Open the .JSON file \n",
    "with open(filePath, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "for paper in data['paper']:\n",
    "    print(\"Paper ID:\", paper['id'])\n",
    "    decision = paper['preliminary_decision'].lower()  \n",
    "    print(\"Preliminary Decision:\", decision)\n",
    "\n",
    "\n",
    "    if decision in decisionCounts:\n",
    "        decisionCounts[decision] += 1\n",
    "    else:\n",
    "        \n",
    "        decisionCounts[decision] = 1\n",
    "\n",
    "    print(\"Reviews:\")\n",
    "    for review in paper['review']:\n",
    "        print(\"  Review ID:\", review['id'])\n",
    "        print(\"  Evaluation:\", review['evaluation'])\n",
    "        print(\"  Confidence:\", review['confidence'])\n",
    "        print(\"  Date:\", review['timespan'])\n",
    "        print(\"\")\n",
    "    print()  \n",
    "    \n",
    "\n",
    "evaluations = []\n",
    "confidences = []\n",
    "orientations = []\n",
    "decisions = []\n",
    "\n",
    "\n",
    "decisionMapping = {\n",
    "    \"no decision\": 0,  \n",
    "    \"accept\": 1,\n",
    "    \"probably reject\": 2,\n",
    "    \"reject\": 3\n",
    "}\n",
    "\n",
    "for paper in data['paper']:\n",
    "    for review in paper['review']:\n",
    "        if 'confidence' in review and review['confidence'] is not None:\n",
    "            confidences.append(int(review['confidence']))\n",
    "\n",
    "\n",
    "medianConfidence = np.median(confidences)  \n",
    "\n",
    "\n",
    "evaluations = []\n",
    "confidences = []\n",
    "orientations = []\n",
    "decisions = []\n",
    "\n",
    "for paper in data['paper']:\n",
    "    paperDecision = paper['preliminary_decision']\n",
    "    # Converting the decision, in text, into a numerical code\n",
    "    \n",
    "    decisionCode = decisionMapping.get(paperDecision, 0)  \n",
    "\n",
    "    for review in paper['review']:\n",
    "        if 'evaluation' in review and review['evaluation'] is not None:\n",
    "            evaluations.append(int(review['evaluation']))\n",
    "        else:\n",
    "            nullValuesCount += 1\n",
    "\n",
    "        if 'confidence' in review and review['confidence'] is not None:\n",
    "            confidences.append(int(review['confidence']))\n",
    "        else:\n",
    "            nullValuesCount += 1\n",
    "            confidences.append(int(medianConfidence))  # assuming medianConfidence is calculated elsewhere\n",
    "\n",
    "        if 'orientation' in review and review['orientation'] is not None:\n",
    "            orientations.append(int(review['orientation']))\n",
    "        else:\n",
    "            nullValuesCount += 1\n",
    "        \n",
    "        # Append the decision code for each review\n",
    "        decisions.append(decisionCode)\n",
    "\n",
    "for paper in data['paper']:\n",
    "    for review in paper['review']:\n",
    "        if 'decision' in review:\n",
    "            \n",
    "            decisionClass = review['decision']\n",
    "        else:\n",
    "            decisionClass = 0  \n",
    "\n",
    "       # decisions.append(decisionClass)\n",
    "\n",
    "print(f\"There are combined {nullValuesCount} null values for orientation, confidence and evaluation.\")\n",
    "\n",
    "evaluationsNP = np.array(evaluations)\n",
    "\n",
    "\n",
    "\n",
    "confidencesArray = np.array(confidences)\n",
    "meanConfidence = np.mean(confidencesArray)\n",
    "medianConfidence = np.median(confidencesArray)\n",
    "\n",
    "print(f\"The length of 'confidences' is {len(confidences)}\")\n",
    "print(f\"The length of 'evaluations' is {len(evaluations)}\")"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#This section is for DBSCAN\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "#The vectors are defined from the dataset\n",
    "df = pd.DataFrame({\n",
    "    'Evaluation': evaluations,\n",
    "    'Confidence': confidences,\n",
    "    'Orientation': orientations,\n",
    "    'Decision': decisions\n",
    "})\n",
    "\n",
    "X = df[['Confidence', 'Orientation', 'Decision']]\n",
    "scaler = StandardScaler()\n",
    "xScaled = scaler.fit_transform(X)\n",
    "\n",
    "#Note : when using a esp value above 1.5 we do only get one cluster. \n",
    "# Here i am defining the hyperparameters i want to test\n",
    "# EPSILON : maximum distance between two samples for one to be considered in the neighborhood of some other\n",
    "epsilonValues = [0.5, 1, 1.1, 1.3, 1.5]  \n",
    "# The number of samples in a neighborhood for a point to be considered as a core point\n",
    "minSamplesValues = [5, 10, 15, 20, 25]  \n",
    "\n",
    "for epsilon in epsilonValues:\n",
    "    for minSamples in minSamplesValues:\n",
    "        dbscan = DBSCAN(eps=epsilon, min_samples=minSamples)\n",
    "        clusterLabels = dbscan.fit_predict(xScaled)\n",
    "\n",
    "        # Silhouette Score can be used but might be less meaningful for DBSCAN\n",
    "        # Especially when the number of noise points is high or clusters are of varied density\n",
    "        if len(np.unique(clusterLabels)) > 1:  \n",
    "            silhouetteAvg = silhouette_score(xScaled, clusterLabels)\n",
    "            print(f\"DBSCAN with eps={epsilon}, min_samples={minSamples}, there are {len(np.unique(clusterLabels))} cluster ,silhouette score: {silhouetteAvg}\")\n",
    "            \n",
    "           \n",
    "           \n",
    "            silhouetteAvg = silhouette_score(xScaled, clusterLabels)\n",
    "            daviesBouldin = davies_bouldin_score(xScaled, clusterLabels)\n",
    "            \n",
    "            print(f\"DBSCAN with eps={epsilon}, min_samples={minSamples}, clusters: {len(np.unique(clusterLabels))}, silhouette: {silhouetteAvg}, davies-bouldin index: {daviesBouldin}\")\n",
    "            \n",
    "        else:\n",
    "            #If there are only one cluster the silhouette score cannot be computed\n",
    "            #This because the silhouette score is determined by the relationship between the clusters\n",
    "            print(f\"DBSCAN with eps={epsilon}, min samples={minSamples} found only one single cluster\")\n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acbbd8c457193c37",
   "execution_count": 0
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
