{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statistics\n",
    "# Path to your JSON file\n",
    "#c\n",
    "filePath = 'dataset/reviews.json'\n",
    "\n",
    "decisionCounts = {\n",
    "    'accept': 0,\n",
    "    'probably reject': 0,\n",
    "    'reject': 0,\n",
    "    'no decision': 0\n",
    "}\n",
    "\n",
    "# Lists to store the feature data\n",
    "evaluations = []\n",
    "confidences = []\n",
    "orientations = []\n",
    "missingValuesPositions = []\n",
    "nullValuesCount= 0\n",
    "\n",
    "\n",
    "with open(filePath, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# \n",
    "for paper in data['paper']:\n",
    "    print(\"Paper ID:\", paper['id'])\n",
    "    decision = paper['preliminary_decision'].lower()  \n",
    "    print(\"Preliminary Decision:\", decision)\n",
    "\n",
    "    \n",
    "    if decision in decisionCounts:\n",
    "        decisionCounts[decision] += 1\n",
    "    else:\n",
    "        decisionCounts[decision] = 1\n",
    "\n",
    "    print(\"Reviews:\")\n",
    "    for review in paper['review']:\n",
    "        print(\"  Review ID:\", review['id'])\n",
    "        print(\"  Evaluation:\", review['evaluation'])\n",
    "        print(\"  Confidence:\", review['confidence'])\n",
    "        print(\"  Date:\", review['timespan'])\n",
    "        print(\"\")\n",
    "    print()  \n",
    "    \n",
    "    \n"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# For finding the median confidence\n",
    "for paper in data['paper']:\n",
    "    for review in paper['review']:\n",
    "        if 'confidence' in review and review['confidence'] is not None:\n",
    "            confidences.append(int(review['confidence']))\n",
    "\n",
    "\n",
    "medianConfidence = np.median(confidences)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T21:13:23.970644500Z",
     "start_time": "2024-04-26T21:13:23.936640300Z"
    }
   },
   "id": "173a9d6ae4099e41",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#This section is for datacollection\n",
    "#The dataset is found here ---->   https://archive.ics.uci.edu/dataset/410/paper+reviews\n",
    "#The dataset is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license\n",
    "\n",
    "\n",
    "evaluations = []\n",
    "confidences = []\n",
    "orientations = []\n",
    "decisions = []\n",
    "\n",
    "\n",
    "decisionMapping = {\n",
    "    \"no decision\": 0,  \n",
    "    \"accept\": 1,\n",
    "    \"probably reject\": 2,\n",
    "    \"reject\": 3\n",
    "}\n",
    "\n",
    "for paper in data['paper']:\n",
    "    paperDecision = paper['preliminary_decision']\n",
    "    # Converting the decision, in text, into integers\n",
    "    \n",
    "    decisionCode = decisionMapping.get(paperDecision, 0)  \n",
    "\n",
    "    for review in paper['review']:\n",
    "        if 'evaluation' in review and review['evaluation'] is not None:\n",
    "            evaluations.append(int(review['evaluation']))\n",
    "        else:\n",
    "            nullValuesCount += 1\n",
    "\n",
    "        if 'confidence' in review and review['confidence'] is not None:\n",
    "            confidences.append(int(review['confidence']))\n",
    "        else:\n",
    "            nullValuesCount += 1\n",
    "            confidences.append(int(medianConfidence))  \n",
    "\n",
    "        if 'orientation' in review and review['orientation'] is not None:\n",
    "            orientations.append(int(review['orientation']))\n",
    "        else:\n",
    "            nullValuesCount += 1\n",
    "        \n",
    "        # Append the decision for each review\n",
    "        decisions.append(decisionCode)\n",
    "\n",
    "for paper in data['paper']:\n",
    "    for review in paper['review']:\n",
    "        if 'decision' in review:\n",
    "            \n",
    "            decisionClass = review['decision']\n",
    "        else:\n",
    "            decisionClass = 0  \n",
    "\n",
    "       # decisions.append(decisionClass)\n",
    "\n",
    "\n",
    "\n",
    "#for paper in data['paper']:\n",
    "#    print(r\"Paper ID:\", paper['id'])\n",
    "#    for review in paper['review']:\n",
    "#        print(r\"Review nr:\", review['id'])\n",
    "#        if 'evaluation' in review:\n",
    "#            if review['evaluation'] is not None:\n",
    "#                evaluations.append(int(review['evaluation']))\n",
    "#            else:\n",
    "#                nullValuesCount = nullValuesCount + 1\n",
    "#\n",
    "#                \n",
    "#                \n",
    "#        if 'confidence' in review:\n",
    "#            if review['confidence'] is not None:\n",
    "#                confidences.append(int(review['confidence']))\n",
    "#            else:\n",
    "#                nullValuesCount = nullValuesCount + 1\n",
    "#                confidences.append(int(medianConfidence))\n",
    "#                \n",
    "#\n",
    "#\n",
    "#\n",
    "#        if 'orientation' in review:\n",
    "#            if review['orientation'] is not None:\n",
    "#                orientations.append(int(review['orientation']))\n",
    "#            else:\n",
    "#                nullValuesCount = nullValuesCount + 1\n",
    "\n",
    "print(f\"There are combined {nullValuesCount} null values for orientation, confidence and evaluation.\")\n",
    "\n",
    "evalu = np.array(evaluations)\n",
    "meanEvalu = np.mean(evalu)\n",
    "medianEvalu = np.median(evalu)\n",
    "modeEvalu = stats.mode(evalu)\n",
    "stddDevEvalu = np.std(evalu)\n",
    "q1Evalu = np.percentile(evalu, 25)\n",
    "q3Evalu = np.percentile(evalu, 75)\n",
    "\n",
    "# Calculate statistics\n",
    "conf = np.array(confidences)\n",
    "meanConf = np.mean(conf)\n",
    "medianConf = np.median(conf)\n",
    "modeConf = stats.mode(conf)\n",
    "stddDevConfi = np.std(conf)\n",
    "q1Conf = np.percentile(conf, 25)\n",
    "q3Conf = np.percentile(conf, 75)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Decision Counts:\")\n",
    "for decision, count in decisionCounts.items():\n",
    "    print(f\"  {decision.title()}: {count}\")\n",
    "\n",
    "print(f\"The length of 'confidences' is {len(confidences)}\")\n",
    "print(f\"The length of 'evaluations' is {len(evaluations)}\")\n",
    "print(int(medianConfidence))\n",
    "\n",
    "\n",
    "print(\"Decision Counts:\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8d617e38bd5f40e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "#This is used for converting the numerical decision classes back to text for having labels in text form\n",
    "reverseDecisionMapping = {value: key for key, value in decisionMapping.items()}\n",
    "decision_labels = [reverseDecisionMapping[decision] for decision in decisions]\n",
    "\n",
    "print(reverseDecisionMapping)\n",
    "\n",
    "dataFrame = pd.DataFrame({\n",
    "    'Decision': decision_labels,\n",
    "    'Evaluations': evaluations,\n",
    "    'Confidences': confidences\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Decision', y='Evaluations', data=dataFrame)  \n",
    "plt.title('Boxplot of Evaluations by Decision Class')\n",
    "plt.ylabel('Evaluations')  # or 'Confidences'\n",
    "plt.xlabel('Decision Class')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.show()\n",
    "\n",
    "print(decisions)\n",
    "print(f\"Decisions length : {len(decisions)}, evaluations length : {len(evaluations)}, confidences length : {len(confidences)}\")\n",
    "\n",
    "\n",
    "# Creating the scatter plot\n",
    "# Pairplots used to find correlations in the scatter plots\n",
    "# This plots every numeric column against every other numeric column and colors points by 'Decision'\n",
    "\n",
    "\n",
    "pairplotFigure = sns.pairplot(dataFrame, hue='Decision', palette='viridis',\n",
    "                            plot_kws={'alpha': 0.6, 's': 80, 'edgecolor': 'k'})\n",
    "pairplotFigure.fig.suptitle('Pairplot of Evaluations and Confidences by Decision Class', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap('viridis', len(reverseDecisionMapping))\n",
    "norm = plt.Normalize(vmin=0, vmax=len(reverseDecisionMapping) - 1)\n",
    "\n",
    "\n",
    "scatter = plt.scatter(evaluations, confidences, c=decisions, cmap=cmap, norm=norm)\n",
    "plt.title('Scatter Plot of Evaluations and Confidences by Decision Class')\n",
    "plt.xlabel('Evaluations')\n",
    "plt.ylabel('Confidences')\n",
    "\n",
    "\n",
    "\n",
    "# Creating the histogram\n",
    "plt.figure(figsize=(10, 6)) \n",
    "for decisionCode in set(decisions):\n",
    "    label = reverseDecisionMapping[decisionCode]  \n",
    "    plt.hist([evaluations[i] for i in range(len(evaluations)) if decisions[i] == decisionCode], bins=20, alpha=0.5, label=label)\n",
    "plt.title('Histogram of Evaluations by Decision Class')\n",
    "plt.xlabel('Evaluations')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Creating the Density Plot\n",
    "for decisionCode in set(decisions):\n",
    "    label = reverseDecisionMapping[decisionCode]  \n",
    "    sns.kdeplot([evaluations[i] for i in range(len(evaluations)) if decisions[i] == decisionCode], label=label)\n",
    "plt.title('Density Plot of Evaluations by Decision Class')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f7283b2f9244b94",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#This section is for linear and Lasso regression\n",
    "#predicting the decisions classification based on evaluation\n",
    "#This works\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(evaluations)\n",
    "print(decisions)\n",
    "\n",
    "#Dataframe of features\n",
    "df = pd.DataFrame({\n",
    "    'Evaluation': evaluations,\n",
    "    'Confidence': confidences,\n",
    "    'Orientation': orientations,\n",
    "    'Decision': decisions\n",
    "})\n",
    "\n",
    "\n",
    "X = np.array(df['Decision']).reshape(-1, 1)  \n",
    "y = np.array(df['Evaluation']) \n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "trainingProportion = 0.62\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=1.0 - trainingProportion, random_state=42)\n",
    "\n",
    "# We also create a linear regression model for comparing the two\n",
    "linearModel = LinearRegression()\n",
    "linearModel.fit(xTrain, yTrain)\n",
    "linearPred = linearModel.predict(xTest)\n",
    "\n",
    "#MSE (mean squared error) is a meausurement on difference between the observed actual outcomes and the predicted outcomes.\n",
    "#We want the MSE to be as close to 0 as possible\n",
    "\n",
    "#R-squared, also known as the coefficient of determination, measures the proportion of the variance\n",
    "\n",
    "\n",
    "# MSE and R^2 for linear model\n",
    "linearMSE = mean_squared_error(yTest, linearPred)\n",
    "linearR2 = r2_score(yTest, linearPred)\n",
    "\n",
    "\n",
    "#For tuning the Lasso model we can edit the alpha parameter\n",
    "#We can also apply scaling of input features\n",
    "#Alpha is the regularization parameter\n",
    "# Lasso model\n",
    "\n",
    "lassoModel = Lasso(alpha=5)\n",
    "lassoModel.fit(xTrain, yTrain)\n",
    "lassoPred = lassoModel.predict(xTest)\n",
    "\n",
    "# MSE and R^2 for linear model\n",
    "lassoMSE = mean_squared_error(yTest, lassoPred)\n",
    "lassoR2 = r2_score(yTest, lassoPred)\n",
    "\n",
    "# Plotting the Linear and Lasso Regression\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X, y, color='green', label='Actual data points', alpha=0.5)\n",
    "plt.plot(xTest, linearPred, color='red', label='Linear Regression Line')\n",
    "plt.plot(xTest, lassoPred, color='blue', label='Lasso Regression Line', linestyle='--')\n",
    "plt.xlabel(\"Decisions\")\n",
    "plt.ylabel(\"Evaluations\")\n",
    "plt.title(\"Lasso regression\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Finding the size of the training set\n",
    "totalDataSize = len(df)\n",
    "trainSize = len(xTrain)\n",
    "testSize = len(xTest)\n",
    "trainPercentage = (trainSize / totalDataSize) * 100\n",
    "testPercentage = (testSize / totalDataSize) * 100\n",
    "\n",
    "print('For this test:')\n",
    "print(f\"Total data size: {totalDataSize}\")\n",
    "print(f\"Training data size: {trainSize}, which is ({trainPercentage}%)\")\n",
    "print(f\"Testing data size: {testSize}, which is ({testPercentage}%)\")\n",
    "\n",
    "print('')\n",
    "\n",
    "print(f'In this test {trainingProportion*100}% of of the data (')\n",
    "print(f'MSE for linear regression model: {linearMSE}')\n",
    "print(f'R² Score for linear regression model: {linearR2}')\n",
    "print(f'MSE for lasso model: {lassoMSE}')\n",
    "print(f'R² Score for lasso model: {lassoR2}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c6567a031571e44",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Gathering the regression stats\n",
    "\n",
    "yTrainLassoreg = pd.Series(yTrain)\n",
    "yTestLassoreg = pd.Series(yTest)\n",
    "\n",
    "dataRange = [-2, -1, 0 ,1 ,2]\n",
    "\n",
    "\n",
    "trainClasses = pd.cut(yTrainLassoreg, dataRange, include_lowest=False, right=False)\n",
    "testClasses = pd.cut(yTestLassoreg, dataRange, include_lowest=False, right=False)\n",
    "\n",
    "\n",
    "trainClassDistribution = trainClasses.value_counts().sort_index()\n",
    "trainClassPercentage = trainClassDistribution / len(yTrainLassoreg) * 100\n",
    "\n",
    "testClassDistribution = testClasses.value_counts().sort_index()\n",
    "testClassPercentage = testClassDistribution / len(yTestLassoreg) * 100\n",
    "\n",
    "\n",
    "print('')\n",
    "print('Training Class Distr:')\n",
    "\n",
    "print(trainClassDistribution)\n",
    "\n",
    "print('')\n",
    "print('Training Perc:')\n",
    "\n",
    "print(trainClassPercentage)\n",
    "\n",
    "\n",
    "print('')\n",
    "print('Test dist:')\n",
    "\n",
    "print(testClassDistribution)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Test Perce:')\n",
    "print(testClassPercentage)\n",
    "\n",
    "\n",
    "\n",
    "print('Training stats:')\n",
    "print(yTrainLassoreg.describe())\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Frequency of each unique value in the training data:')\n",
    "print(yTrainLassoreg.value_counts().sort_index())\n",
    "\n",
    "print('')\n",
    "\n",
    "\n",
    "print('Test stats')\n",
    "print(yTestLassoreg.describe())\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Frequency of each value in the test data:')\n",
    "print(yTestLassoreg.value_counts().sort_index())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1467c525d27036b4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#This section is for linear regression\n",
    "#This works\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "\n",
    "X = np.array(confidences).reshape(-1, 1)\n",
    "y = np.array(evaluations)\n",
    "\n",
    "# Creating a DataFrame\n",
    "dataFrame = pd.DataFrame({\n",
    "    'Confidence': confidences,\n",
    "    'Evaluation': evaluations\n",
    "})\n",
    "\n",
    "# Finding the mean and median for every confidence level\n",
    "#This is used for, in the end, evaluate the regression line\n",
    "\n",
    "meanEvaluations = dataFrame.groupby('Confidence').Evaluation.mean().reset_index()\n",
    "medianEvaluations = dataFrame.groupby('Confidence').Evaluation.median().reset_index()\n",
    "\n",
    "polyFeatures = PolynomialFeatures(degree=2, include_bias=False)\n",
    "XPoly = polyFeatures.fit_transform(X)\n",
    "\n",
    "# Here we are splitting the dataset into training and testing sets\n",
    "trainingProportion = 0.7\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(XPoly, y, test_size=1.0 - trainingProportion, random_state=42)\n",
    "\n",
    "# Here we initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(xTrain, yTrain)\n",
    "\n",
    "\n",
    "yPred = model.predict(xTest)\n",
    "\n",
    "\n",
    "mse = mean_squared_error(yTest, yPred)\n",
    "r2 = r2_score(yTest, yPred)\n",
    "\n",
    "print('Coefficients: ')\n",
    "print(model.coef_)\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "print('Intercept: ')\n",
    "print(model.intercept_)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(1, (10,8))\n",
    "plt.scatter(X, y, color='green', label='Actual data points', alpha=0.5)\n",
    "plt.plot(meanEvaluations['Confidence'], meanEvaluations['Evaluation'], 'bo-', label='Mean Evaluations')\n",
    "plt.plot(medianEvaluations['Confidence'], medianEvaluations['Evaluation'], 'ro-', label='Median Evaluations')\n",
    "plt.scatter(xTest[:, 0], yPred, color='grey', label='Predictions', alpha=0.5)\n",
    "plt.xlabel(\"Confidence\")\n",
    "plt.ylabel(\"Evaluation\")\n",
    "plt.title(\"Polynomial Regression on Review Data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R² Score: {r2}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a4ea538c8715838",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#This section is for the Decision Tree model\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "import graphviz\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Evaluation': evaluations,\n",
    "    'Confidence': confidences,\n",
    "    'Orientation': orientations,\n",
    "    'Decision': decisions\n",
    "})\n",
    "\n",
    "\n",
    "X = np.array(df['Decision']).reshape(-1, 1)  \n",
    "y = np.array(df['Evaluation']) \n",
    "\n",
    "#The Decision Tree model has plenty of Hyperparameters.\n",
    "\n",
    "\n",
    "treeModel = DecisionTreeRegressor(\n",
    "    max_depth=99999999999999,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=6,\n",
    "    max_features=None,\n",
    "    max_leaf_nodes=200000000,\n",
    "    min_impurity_decrease=0.000000000000000000000000001,\n",
    "    splitter='best',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "trainingProportion = 0.62\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=1.0 - trainingProportion, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "treeModel.fit(xTrain, yTrain)\n",
    "\n",
    "\n",
    "yPredTree = treeModel.predict(xTest)\n",
    "\n",
    "\n",
    "mseTree = mean_squared_error(yTest, yPredTree)\n",
    "r2Tree = r2_score(yTest, yPredTree)\n",
    "print(f'Mean Squared Error: {mseTree}')\n",
    "print(f'R^2 Score: {r2Tree}')\n",
    "\n",
    "dot_data = export_graphviz(treeModel, filled=True, rounded=True, special_characters=True)\n",
    "\n",
    "totalDataSize = len(df)\n",
    "trainSize = len(xTrain)\n",
    "testSize = len(xTest)\n",
    "trainPercentage = (trainSize / totalDataSize) * 100\n",
    "testPercentage = (testSize / totalDataSize) * 100\n",
    "\n",
    "print('For this test:')\n",
    "print(f\"Total data size: {totalDataSize}\")\n",
    "print(f\"Training data size: {trainSize}, which is ({trainPercentage}%)\")\n",
    "print(f\"Testing data size: {testSize}, which is ({testPercentage}%)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "graph = graphviz.Source(dot_data, format=\"png\") \n",
    "graph\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X, y, color='green', label='Actual data')\n",
    "plt.scatter(xTest, yPredTree, color='red', label='Predicted data', alpha=0.5)\n",
    "plt.xlabel(\"Decisions\")\n",
    "plt.ylabel(\"Evaluations\")\n",
    "plt.title(\"Decision Tree Regression on Review Data\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e8eb45e1802b75f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#This section is for the Decision Tree model\n",
    "#By using all features in matrix\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Evaluation': evaluations,\n",
    "    'Confidence': confidences,\n",
    "    'Orientation': orientations,\n",
    "    'Decision': decisions\n",
    "})\n",
    "\n",
    "\n",
    "X = df[['Confidence', 'Orientation', 'Decision']]  \n",
    "y = df['Evaluation']\n",
    "\n",
    "#The Decision Tree model has plenty of Hyperparameters.\n",
    "\n",
    "\n",
    "treeModel = DecisionTreeRegressor(\n",
    "    max_depth=9999,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=6,\n",
    "    max_features=None,\n",
    "    max_leaf_nodes=200000000,\n",
    "    min_impurity_decrease=0.000000000000000000000000001,\n",
    "    splitter='best',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "trainingProportion = 0.62\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=1.0 - trainingProportion, random_state=42)\n",
    "\n",
    "\n",
    "treeModel.fit(xTrain, yTrain)\n",
    "\n",
    "\n",
    "yPredTree = treeModel.predict(xTest)\n",
    "\n",
    "\n",
    "mseTree = mean_squared_error(yTest, yPredTree)\n",
    "r2Tree = r2_score(yTest, yPredTree)\n",
    "print(f'Mean Squared Error: {mseTree}')\n",
    "print(f'R^2 Score: {r2Tree}')\n",
    "dot_data = export_graphviz(treeModel, filled=True, rounded=True, special_characters=True)\n",
    "\n",
    "\n",
    "#Finding the size of the training set\n",
    "totalDataSize = len(df)\n",
    "trainSize = len(xTrain)\n",
    "testSize = len(xTest)\n",
    "trainPercentage = (trainSize / totalDataSize) * 100\n",
    "testPercentage = (testSize / totalDataSize) * 100\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "print('For this test:')\n",
    "print(f\"Total data size: {totalDataSize}\")\n",
    "print(f\"Training data size: {trainSize}, which is ({trainPercentage}%)\")\n",
    "print(f\"Testing data size: {testSize}, which is ({testPercentage}%)\")\n",
    "\n",
    "\n",
    "graph = graphviz.Source(dot_data, format=\"png\") \n",
    "graph\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X['Decision'], y, color='green', label='Actual data') \n",
    "plt.scatter(xTest['Decision'], yPredTree, color='red', label='Predicted data', alpha=0.5) \n",
    "plt.xlabel(\"Decisions\")\n",
    "plt.ylabel(\"Evaluations\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa19370984705448",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Showing the distrobution stats:\n",
    "\n",
    "\n",
    "trainClassDistribution = yTrain.value_counts()\n",
    "testClassDistribution = yTest.value_counts()\n",
    "\n",
    "\n",
    "trainClassPercentage = (trainClassDistribution / len(yTrain)) * 100\n",
    "testClassPercentage = (testClassDistribution / len(yTest)) * 100\n",
    "\n",
    "print(\"Training set class distribution:\")\n",
    "print(trainClassDistribution)\n",
    "print(\"Training set class percentages:\")\n",
    "print(trainClassPercentage)\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "print(\"Test set class distribution:\")\n",
    "print(testClassDistribution)\n",
    "print(\"Test set class percentages:\")\n",
    "print(testClassPercentage)\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "print(\"Training set class distribution:\")\n",
    "print(trainClassDistribution)\n",
    "print(\"Training set class percentages:\")\n",
    "print(trainClassPercentage)\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "print(\"Test set class distribution:\")\n",
    "print(testClassDistribution)\n",
    "print(\"Test set class percentages:\")\n",
    "print(testClassPercentage)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23aadb9373cfaefe",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
